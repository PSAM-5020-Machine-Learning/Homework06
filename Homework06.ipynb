{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework06\n",
    "\n",
    "Exercises to practice pandas, data analysis and regression\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Understand the effects of pre-processing data\n",
    "- Get familiar with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the difference between regression and classification tasks\n",
    "- Build intuition for different regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import LinearRegression, SGDRegressor\n",
    "from data_utils import regression_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/DM-GY-9103-2024F-H/WK02).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel.\n",
    "\n",
    "#### WARNING\n",
    "\n",
    "Like we mentioned in class, this dataset is being used for these exercises due to the level of detail in the dataset and the rigorous process that was used in collecting the data.\n",
    "\n",
    "This is a very specific dataset and should not be used to draw general conclusions about people, bodies, or anything else that is not related to the distribution of physical features of U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested data\n",
    "\n",
    "This is that *nested* dataset from Week 02.\n",
    "\n",
    "# ü§î\n",
    "\n",
    "Let's load it into a `DataFrame` to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.DataFrame.from_records(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üòìüôÑ\n",
    "\n",
    "That didn't work too well. We ended up with objects in our columns.\n",
    "\n",
    "Luckily, our `DataFrame` library has a function called [`json_normalize()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) that can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. `DataFrames` are magic.\n",
    "\n",
    "#### Data Exploration\n",
    "\n",
    "Before we start creating models, let's do a little bit of data analysis and get a feeling for the shapes, distributions and relationships of our data.\n",
    "\n",
    "1. Print `min`, `max` and `average` values for all of the features.\n",
    "2. Print `covariance` tables for `age`, `ear.length` and `head.circumference`.\n",
    "3. Plot `age`, `ear.length` and `head.circumference` versus the $1$ *feature* that is most correlated to each of them.\n",
    "\n",
    "Don't forget to *encode* and *normalize* the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Data Exploration here\n",
    "\n",
    "### Encode non-numerical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = ansur_df.select_dtypes(include=['object']).columns.tolist()\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "one_hot_encoded = encoder.fit_transform(ansur_df[categorical_columns])\n",
    "\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "ansur_df_encoded = pd.concat([ansur_df, one_hot_df], axis=1)\n",
    "\n",
    "ansur_df_encoded = ansur_df_encoded.drop(categorical_columns, axis=1)\n",
    "\n",
    "## 1. Print min, max, avg\n",
    "for c in ansur_df_encoded.columns:\n",
    "    print(c, \"\\n\\tmin:\", ansur_df_encoded[c].min())\n",
    "    print(\"\\tmax:\", ansur_df_encoded[c].max())\n",
    "    print(\"\\tavg:\", round(ansur_df_encoded[c].mean(), 3))\n",
    "\n",
    "### Normalize all data\n",
    "ansur_scaler = StandardScaler()\n",
    "ansur_scaled = ansur_scaler.fit_transform(ansur_df_encoded)\n",
    "#display(ansur_scaled)\n",
    "#display(ansur_scaled.describe())\n",
    "\n",
    "## 2. Print Covariances\n",
    "display(ansur_scaled.cov())\n",
    "\n",
    "## 3. Plot features most correlated to age, ear length and head circumference\n",
    "# ear length, weight, head height\n",
    "plt.plot(ansur_scaled[\"age\"], ansur_scaled[\"ear.length\"], marker=\"o\", linestyle=\"\", alpha=0.4)\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"ear length\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ansur_scaled[\"ear.length\"], ansur_scaled[\"weight\"], marker=\"o\", linestyle=\"\", alpha=0.4)\n",
    "plt.xlabel(\"ear length\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ansur_scaled[\"head.circumference\"], ansur_scaled[\"head.height\"], marker=\"o\", linestyle=\"\", alpha=0.4)\n",
    "plt.xlabel(\"head circumference\")\n",
    "plt.ylabel(\"head height\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about these graphs? Or the correlations?<br>\n",
    "Are correlations symmetric? Does the feature most correlated to ear length also have ear length as its most correlated pair?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">Ear length and age have weak correlations, while ear length also has correlations with weight. Weight is almost most correlated with head circumference. I wonder if there is any interactions or ways to predict head circumference based on these features. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Now, we want to create a regression model to predict `head.circumference` from the data.\n",
    "\n",
    "From our [Week 06](https://github.com/PSAM-5020-2025S-A/WK06) notebook, we can create a regression model by following these steps:\n",
    "\n",
    "1. Load dataset (done! üéâ)\n",
    "2. Encode label features as numbers (done! ‚ö°Ô∏è)\n",
    "3. Normalize the data (done! üçæ)\n",
    "4. Separate the outcome variable and the input features\n",
    "5. Create a regression model using all features\n",
    "6. Run model on training data and measure error\n",
    "7. Plot predictions and interpret results\n",
    "8. Run model on test data, measure error, plot predictions, interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Regression Model here\n",
    "\n",
    "## Separate outcome variable and input features\n",
    "features = ansur_scaled.drop(columns=[\"head.circumference\"])\n",
    "head_circumference = ansur_scaled[\"head.circumference\"]\n",
    "\n",
    "## Create a regression model\n",
    "ansur_model = LinearRegression()\n",
    "ansur_model.fit(features, head_circumference)\n",
    "\n",
    "## Measure error on training data\n",
    "predicted_scaled = ansur_model.predict(features)\n",
    "predicted = ansur_scaler.inverse_transform(predicted_scaled)\n",
    "print(regression_error(ansur_df[\"head.circumference\"], predicted[\"head.circumference\"]))\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "head_circumference_original = ansur_df[\"head.circumference\"]\n",
    "head_circumference_predicted = predicted[\"head.circumference\"]\n",
    "\n",
    "# Plot the original and predicted prices\n",
    "plt.plot(sorted(head_circumference_original), marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(sorted(head_circumference_predicted), color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
    "plt.ylabel(\"head circumference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Test Data\n",
    "ANSUR_TEST_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/main/datasets/json/ansur-test.json\"\n",
    "\n",
    "ansur_test_data = object_from_json_url(ANSUR_TEST_FILE)\n",
    "ansur_test_df = pd.json_normalize(ansur_test_data)\n",
    "\n",
    "ansur_test_encoded_df = ansur_test_df.copy()\n",
    "\n",
    "#g_vals = ansur_encoder.transform(ansur_test_df[[\"gender\"]].values)\n",
    "#ansur_test_encoded_df[[\"gender\"]] = g_vals\n",
    "\n",
    "categorical_columns = ansur_df.select_dtypes(include=['object']).columns.tolist()\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "one_hot_encoded = encoder.fit_transform(ansur_test_df[categorical_columns])\n",
    "\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "ansur_test_encoded_df = pd.concat([ansur_test_df, one_hot_df], axis=1)\n",
    "\n",
    "ansur_test_encoded_df = ansur_test_encoded_df.drop(categorical_columns, axis=1)\n",
    "\n",
    "ansur_test_scaled = ansur_scaler.transform(ansur_test_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Run model on test data\n",
    "features_test = ansur_test_scaled.drop(columns=[\"head.circumference\"])\n",
    "head_circumference_test = ansur_test_scaled[\"head.circumference\"]\n",
    "\n",
    "## Create a regression model\n",
    "ansur_model = LinearRegression()\n",
    "ansur_model.fit(features_test, head_circumference_test)\n",
    "\n",
    "## Measure error on training data\n",
    "predicted_scaled_test = ansur_model.predict(features_test)\n",
    "predicted_test = ansur_scaler.inverse_transform(predicted_scaled_test)\n",
    "print(regression_error(ansur_test_df[\"head.circumference\"], predicted_test[\"head.circumference\"]))\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "head_circumference_original_test = ansur_test_df[\"head.circumference\"]\n",
    "head_circumference_predicted_test = predicted_test[\"head.circumference\"]\n",
    "\n",
    "# Plot the original and predicted prices\n",
    "plt.plot(sorted(head_circumference_original_test), marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(sorted(head_circumference_predicted_test), color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
    "plt.ylabel(\"head circumference - test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How well does your model perform?<br>\n",
    "How could you improve it?<br>\n",
    "Are there ranges of circumferences that don't get predicted well?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">The model seems okay, since the Mean Squared Error indicates that on average our prdicted value deviates from the actual valye by about 3.7 units. It seems that medium sized heads (around 570) are better predict than smaller heads (under 560) or bigger heads (over 570). I think we could catagorize head circumference into three groups and train different models for each group.</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
